#!/usr/bin/env python3
import feedparser
import json
import re
from googletrans import Translator
from collections import defaultdict
from datetime import datetime, date, timedelta
import os
import html
import time
import random
import asyncio

# ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚¤ã‚³ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆçµµæ–‡å­—ã‚’ä½¿ç”¨ï¼‰
SERVICE_ICONS = {
    'ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆç³»': 'ğŸ’»',
    'ã‚³ãƒ³ãƒ†ãƒŠç³»': 'ğŸ³',
    'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç³»': 'ğŸŒ',
    'DBã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç³»': 'ğŸ’¾',
    'ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ±åˆ': 'ğŸ”„',
    'é–‹ç™ºç’°å¢ƒ': 'ğŸ‘¨â€ğŸ’»',
    'é‹ç”¨ç®¡ç†': 'ğŸ”§',
    'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£': 'ğŸ”’',
    'ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»ç®¡ç†ãƒ»åˆ†æ': 'ğŸ“Š',
    'AI/ML': 'ğŸ¤–',
    'ã‚³ãƒ³ã‚¿ã‚¯ãƒˆã‚»ãƒ³ã‚¿ãƒ¼': 'ğŸ“',
    'IoT': 'ğŸ“±',
    'ãƒ¡ãƒ‡ã‚£ã‚¢': 'ğŸ¬',
    'è«‹æ±‚ç³»': 'ğŸ’°',
    'ç§»è»¢ã¨è»¢é€ç³»': 'ğŸšš',
    'ãã®ä»–': 'ğŸ“¦'
}

# é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¼·èª¿è¡¨ç¤ºç”¨ï¼‰
IMPORTANT_KEYWORDS = [
    'GA', 'ä¸€èˆ¬æä¾›é–‹å§‹', 'ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼', 'æ–°æ©Ÿèƒ½', 'æ–°ãƒªãƒ¼ã‚¸ãƒ§ãƒ³', 'ãƒªãƒªãƒ¼ã‚¹', 
    'ã‚µãƒãƒ¼ãƒˆçµ‚äº†', 'ä¾¡æ ¼æ”¹å®š', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'è„†å¼±æ€§'
]

# å¤–éƒ¨JSONã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã¨èª¬æ˜ã‚’èª­ã¿è¾¼ã‚€
try:
    _mapping_file = os.path.join(os.path.dirname(__file__), 'service_mappings.json')
    with open(_mapping_file, 'r', encoding='utf-8') as _f:
        _data = json.load(_f)
    CATEGORY_MAPPINGS = _data.get('category_mappings', {})
    SERVICE_DESCRIPTIONS = _data.get('service_descriptions', {})
except Exception:
    CATEGORY_MAPPINGS = {}
    SERVICE_DESCRIPTIONS = {}

# ã‚µãƒ¼ãƒ“ã‚¹ã”ã¨ã®ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°
def get_category(title):
    for svc, cat in CATEGORY_MAPPINGS.items():
        if svc in title:
            return cat, svc
    return 'ãã®ä»–', None

# ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ãƒãƒƒãƒ”ãƒ³ã‚°
def get_service_description(svc):
    return SERVICE_DESCRIPTIONS.get(svc, '')

def strip_html(html_text):
    return re.sub('<[^<]+?>', '', html_text)

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def get_prev_week_range(today=None):
    if today is None:
        today = date.today()
    # 0=Monday, 5=Saturday, 6=Sunday in weekday()
    # Get the week (Sunday to Saturday)
    
    if today.weekday() == 6:
        # Today is Sunday - get previous week
        week_start = today - timedelta(days=7)
        week_end = today - timedelta(days=1)
    else:
        # Monday-Saturday - get this week (find this week's Sunday and Saturday)
        days_since_sunday = (today.weekday() + 1) % 7
        week_start = today - timedelta(days=days_since_sunday)
        # Saturday is 6 days after Sunday
        week_end = week_start + timedelta(days=6)
    
    return week_start, week_end

def is_in_prev_week(pub_date, today=None):
    start, end = get_prev_week_range(today)
    return start <= pub_date <= end

def trim_summary(summary_text, limit=200):
    if len(summary_text) > limit:
        # æ–‡ã®é€”ä¸­ã§åˆ‡ã‚Œãªã„ã‚ˆã†ã«èª¿æ•´
        last_period = summary_text[:limit].rfind('ã€‚')
        if last_period > limit * 0.7:  # 70%ä»¥ä¸Šã®ä½ç½®ã«å¥ç‚¹ãŒã‚ã‚Œã°ã€ãã“ã§åˆ‡ã‚‹
            return summary_text[:last_period+1] + '...'
        return summary_text[:limit-3] + '...'
    return summary_text

def highlight_keywords(text):
    """é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¼·èª¿è¡¨ç¤ºã™ã‚‹"""
    for keyword in IMPORTANT_KEYWORDS:
        text = text.replace(keyword, f'**{keyword}**')
    return text

def is_important_update(title, summary):
    """é‡è¦ãªæ›´æ–°ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    for keyword in IMPORTANT_KEYWORDS:
        if keyword in title or keyword in summary:
            return True
    return False

def generate_toc(categories):
    """ç›®æ¬¡ã‚’ç”Ÿæˆ"""
    toc = ["## ç›®æ¬¡\n"]
    for i, cat in enumerate(categories):
        if cat in SERVICE_ICONS:
            toc.append(f"{i+1}. [{SERVICE_ICONS[cat]} {cat}](#{cat.replace(' ', '-').replace('/', '').lower()})")
    return "\n".join(toc) + "\n\n"

async def safe_translate_async(translator, text, dest='ja', max_retries=2):
    """å®‰å…¨ãªç¿»è¨³å‡¦ç†ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ããƒ»éåŒæœŸç‰ˆï¼‰"""
    if not text or len(text.strip()) == 0:
        return text
        
    for attempt in range(max_retries):
        try:
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            if attempt > 0:
                await asyncio.sleep(random.uniform(1, 3))
            
            result = await translator.translate(text, dest=dest)
            
            if hasattr(result, 'text'):
                return result.text
            else:
                print(f"ç¿»è¨³çµæœãŒä¸æ­£: {type(result)}")
                return text
                
        except Exception as e:
            print(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{max_retries}): {str(e)[:100]}")
            if attempt == max_retries - 1:
                print(f"ç¿»è¨³å¤±æ•—ã€å…ƒãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨: {text[:30]}...")
                return text
    
    return text

async def main_async():
    print("AWSæ›´æ–°æƒ…å ±ã®å–å¾—ã‚’é–‹å§‹ã—ã¾ã™...")
    
    feed_url = 'https://aws.amazon.com/about-aws/whats-new/recent/feed/'
    feed = feedparser.parse(feed_url)
    
    # å‰é€±ï¼ˆæ—¥æ›œï½åœŸæ›œï¼‰ã‚’è¨ˆç®—
    today = date.today()
    prev_sunday, prev_saturday = get_prev_week_range(today)
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
    output_dir = os.path.join(os.path.dirname(__file__), 'output')
    os.makedirs(output_dir, exist_ok=True)
    filename = f"awsupdates_{prev_sunday:%Y-%m-%d}_{prev_saturday:%Y-%m-%d}.md"
    filepath = os.path.join(output_dir, filename)
    out_file = open(filepath, 'w', encoding='utf-8')
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚³ãƒ¡ãƒ³ãƒˆã¨ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å‡ºåŠ›
    print(f"<!-- filepath: {filepath} -->", file=out_file)
    print(f"# AWS æ›´æ–°æƒ…å ± ({prev_sunday:%Y-%m-%d} ï½ {prev_saturday:%Y-%m-%d})\n", file=out_file)
    print(f"å…ˆé€±ã® AWS ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆæƒ…å ±ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚\n", file=out_file)

    print("ç¿»è¨³ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–ä¸­...")
    try:
        translator = Translator()
        # ãƒ†ã‚¹ãƒˆç¿»è¨³
        test_result = await safe_translate_async(translator, "test")
        print(f"ç¿»è¨³ãƒ†ã‚¹ãƒˆçµæœ: {test_result}")
    except Exception as e:
        print(f"ç¿»è¨³ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        translator = None
    
    # ç‰¹å®šã‚µãƒ¼ãƒ“ã‚¹åã‚’è‹±èªã®ã¾ã¾ç¶­æŒã™ã‚‹ãŸã‚ã®ä¾‹å¤–ãƒªã‚¹ãƒˆ
    exceptional_services = ['AWS Control Tower', 'AWS Glue', 'Amazon SageMaker', 'AWS Lambda']
    exceptions_map = {}
    if translator:
        for svc in exceptional_services:
            jp = await safe_translate_async(translator, svc)
            exceptions_map[jp] = svc

    grouped = defaultdict(list)
    service_count = defaultdict(int)

    for entry in feed.entries:
        # å…¬é–‹æ—¥ã‚’æ§‹é€ ä½“ã‹ã‚‰å–å¾—
        if hasattr(entry, 'published_parsed'):
            pub_date = datetime(*entry.published_parsed[:6]).date()
        else:
            continue
        # å‰é€±ã®æœŸé–“å¤–ã¯ã‚¹ã‚­ãƒƒãƒ—
        if not is_in_prev_week(pub_date, today):
            continue
        
        title = entry.title
        link = entry.link
        summary = strip_html(entry.summary)
        category, svc = get_category(title)
        
        # é‡è¦åº¦ã®åˆ¤å®š
        important = is_important_update(title, summary)
        
        item = {
            'title': title, 
            'link': link, 
            'summary': summary, 
            'service': svc,
            'important': important,
            'date': pub_date.strftime('%Y-%m-%d')
        }
        grouped[category].append(item)
        if svc:
            service_count[svc] += 1

    # ã‚«ãƒ†ã‚´ãƒªã®é †åº
    order = [
        'ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆç³»', 'ã‚³ãƒ³ãƒ†ãƒŠç³»', 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç³»', 'DBã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç³»', 'ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ±åˆ',
        'é–‹ç™ºç’°å¢ƒ', 'é‹ç”¨ç®¡ç†', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»ç®¡ç†ãƒ»åˆ†æ', 'AI/ML',
        'ã‚³ãƒ³ã‚¿ã‚¯ãƒˆã‚»ãƒ³ã‚¿ãƒ¼', 'IoT', 'ãƒ¡ãƒ‡ã‚£ã‚¢', 'è«‹æ±‚ç³»', 'ç§»è»¢ã¨è»¢é€ç³»', 'ãã®ä»–'
    ]
    
    # ç›®æ¬¡ã‚’ç”Ÿæˆ
    active_categories = [cat for cat in order if cat in grouped and grouped[cat]]
    print(generate_toc(active_categories), file=out_file)
    
    # Markdownå½¢å¼ã§å‡ºåŠ›
    total_count = 0
    for cat in order:
        if cat not in grouped or not grouped[cat]:
            continue
            
        # ã‚«ãƒ†ã‚´ãƒªè¦‹å‡ºã—ï¼ˆã‚¢ã‚¤ã‚³ãƒ³ä»˜ãï¼‰
        icon = SERVICE_ICONS.get(cat, '')
        print(f"## {icon} {cat}\n", file=out_file)
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        service_items = defaultdict(list)
        for item in grouped[cat]:
            service_items[item['service'] or 'æœªåˆ†é¡'].append(item)
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã”ã¨ã«å‡ºåŠ›
        for service, items in service_items.items():
            # ã‚µãƒ¼ãƒ“ã‚¹åã¨èª¬æ˜ã‚’å‡ºåŠ›
            service_desc = get_service_description(service)
            if service_desc:
                print(f"### {service} - {service_desc}\n", file=out_file)
            else:
                print(f"### {service}\n", file=out_file)
                
            for item in items:
                total_count += 1
                # é‡è¦ãªæ›´æ–°ã«ã¯ç›®ç«‹ã¤ãƒãƒ¼ã‚«ãƒ¼ã‚’è¿½åŠ 
                importance_marker = "ğŸ”¥ " if item['important'] else ""
                
                # ã‚¿ã‚¤ãƒˆãƒ«è¦‹å‡ºã—
                if translator:
                    title_ja = await safe_translate_async(translator, item['title'])
                else:
                    title_ja = item['title']
                
                # ç¿»è¨³å¾Œã«ä¾‹å¤–ã‚µãƒ¼ãƒ“ã‚¹åã‚’å…ƒã®è‹±èªè¡¨è¨˜ã«æˆ»ã™
                for jp, orig in exceptions_map.items():
                    title_ja = title_ja.replace(jp, orig)
                
                # é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¼·èª¿
                title_ja = highlight_keywords(title_ja)
                
                print(f"#### {importance_marker}{title_ja}", file=out_file)
                
                # é …ç›®ã®è©³ç´°ã‚’ãƒªã‚¹ãƒˆã§å‡ºåŠ›
                print(f"- **æ—¥ä»˜**: {item['date']}", file=out_file)
                print(f"- **ãƒªãƒ³ã‚¯**: {item['link']}", file=out_file)
                
                # æ¦‚è¦ã®ç¿»è¨³
                if translator:
                    summary_ja = await safe_translate_async(translator, item['summary'])
                else:
                    summary_ja = item['summary']
                
                # ç¿»è¨³å¾Œã«ä¾‹å¤–ã‚µãƒ¼ãƒ“ã‚¹åã‚’å…ƒã®è‹±èªè¡¨è¨˜ã«æˆ»ã™
                for jp, orig in exceptions_map.items():
                    summary_ja = summary_ja.replace(jp, orig)
                
                summary_ja = trim_summary(summary_ja)
                summary_ja = highlight_keywords(summary_ja)
                
                print(f"- **æ¦‚è¦**: {summary_ja}\n", file=out_file)
                
                # åŒºåˆ‡ã‚Šç·šã‚’è¿½åŠ 
                print("---\n", file=out_file)
    
    # çµ±è¨ˆæƒ…å ±
    print("## ğŸ“Š çµ±è¨ˆæƒ…å ±\n", file=out_file)
    print(f"- **åˆè¨ˆ**: {total_count} ä»¶ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ", file=out_file)
    
    # ã‚µãƒ¼ãƒ“ã‚¹åˆ¥ã®æ›´æ–°æ•°
    if service_count:
        print("- **ã‚µãƒ¼ãƒ“ã‚¹åˆ¥æ›´æ–°æ•°**:", file=out_file)
        for svc, count in sorted(service_count.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  - {svc}: {count} ä»¶", file=out_file)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    print("\n---", file=out_file)
    print(f"*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ {datetime.now():%Y-%m-%d} ã«è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*", file=out_file)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã‚‹
    out_file.close()
    print(f"æ›´æ–°æƒ…å ±ã‚’ {filepath} ã«å‡ºåŠ›ã—ã¾ã—ãŸã€‚")

def main():
    asyncio.run(main_async())

if __name__ == '__main__':
    main()